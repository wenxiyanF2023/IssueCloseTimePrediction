{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('issues.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert the loaded data into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "df['closed_at'] = pd.to_datetime(df['closed_at'])\n",
    "\n",
    "# Calculate the time to close by subtracting 'created_at' from 'closed_at'\n",
    "df['time_to_close'] = df['closed_at'] - df['created_at']\n",
    "df['time_to_close_hours'] = df['time_to_close'].dt.total_seconds() / 3600\n",
    "# drop created_at, closed_at, time_to_close\n",
    "df.drop(columns=['time_to_close'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k7/166zln1s58l1tw9yx4b7tgd00000gn/T/ipykernel_69304/2839442781.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['title'].fillna('', inplace=True)\n",
      "/var/folders/k7/166zln1s58l1tw9yx4b7tgd00000gn/T/ipykernel_69304/2839442781.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['body'].fillna('', inplace=True)\n",
      "[nltk_data] Downloading package punkt to /Users/wenxiyang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/wenxiyang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/wenxiyang/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/wenxiyang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "import contractions\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# Fill NaN values with empty string before combining\n",
    "df['title'].fillna('', inplace=True)\n",
    "df['body'].fillna('', inplace=True)\n",
    "df['text'] = df['title'] + \" \" + df['body']\n",
    "\n",
    "# Step 1: Replace line breaks and quotation marks\n",
    "df['text_parsed'] = df['text'].str.replace(\"\\r\", \" \")\n",
    "df['text_parsed'] = df['text_parsed'].str.replace(\"\\n\", \" \")\n",
    "df['text_parsed'] = df['text_parsed'].str.replace('\"', '')\n",
    "df['text_parsed'] = df['text_parsed'].str.lower()\n",
    "\n",
    "# Step 2: Expand Contractions\n",
    "df['text_parsed'] = df['text_parsed'].apply(lambda x: contractions.fix(x))\n",
    "\n",
    "# Step 3: Remove punctuation and possessive pronoun terminations\n",
    "punctuation_signs = string.punctuation\n",
    "df['text_parsed'] = df['text_parsed'].apply(lambda x: ''.join([char for char in x if char not in punctuation_signs]))\n",
    "df['text_parsed'] = df['text_parsed'].str.replace(\"'s\", \"\", regex=True)\n",
    "\n",
    "# Step 4: Lemmatize text\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    text_words = nltk.word_tokenize(text)\n",
    "    lemmatized_list = [wordnet_lemmatizer.lemmatize(word, pos=\"v\") for word in text_words]\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    return lemmatized_text\n",
    "\n",
    "df['text_parsed'] = df['text_parsed'].apply(lambda x: lemmatize_text(x))\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "df['text_parsed'] = df['text_parsed'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>is_pull_request</th>\n",
       "      <th>author_association</th>\n",
       "      <th>time_to_close_hours</th>\n",
       "      <th>text</th>\n",
       "      <th>text_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[DOM] Fix package.json files for #28784</td>\n",
       "      <td>Missed some files for the react-server disallo...</td>\n",
       "      <td>2024-04-08 22:41:51+00:00</td>\n",
       "      <td>2024-04-08 22:49:19+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>COLLABORATOR</td>\n",
       "      <td>0.124444</td>\n",
       "      <td>[DOM] Fix package.json files for #28784 Missed...</td>\n",
       "      <td>dom fix packagejson file 28784 miss file react...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[DOM] disallow client entrypoints with react-s...</td>\n",
       "      <td>`react-server` precludes loading code that exp...</td>\n",
       "      <td>2024-04-08 22:26:02+00:00</td>\n",
       "      <td>2024-04-08 22:37:06+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>COLLABORATOR</td>\n",
       "      <td>0.184444</td>\n",
       "      <td>[DOM] disallow client entrypoints with react-s...</td>\n",
       "      <td>dom disallow client entrypoints reactserver co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[TestUtils] Build limited test-utils</td>\n",
       "      <td>We landed a flag to disable test utils in many...</td>\n",
       "      <td>2024-04-08 18:02:46+00:00</td>\n",
       "      <td>2024-04-08 19:27:20+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>COLLABORATOR</td>\n",
       "      <td>1.409444</td>\n",
       "      <td>[TestUtils] Build limited test-utils We landed...</td>\n",
       "      <td>testutils build limit testutils land flag disa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Flight] Allow lazily resolving outlined models</td>\n",
       "      <td>We used to assume that outlined models are emi...</td>\n",
       "      <td>2024-04-08 15:24:01+00:00</td>\n",
       "      <td>2024-04-08 19:40:11+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>COLLABORATOR</td>\n",
       "      <td>4.269444</td>\n",
       "      <td>[Flight] Allow lazily resolving outlined model...</td>\n",
       "      <td>flight allow lazily resolve outline model use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Add Promise as a child test to Flight fixture</td>\n",
       "      <td>Adds a test for promise as a child that was fi...</td>\n",
       "      <td>2024-04-08 10:46:31+00:00</td>\n",
       "      <td>2024-04-08 15:06:17+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>COLLABORATOR</td>\n",
       "      <td>4.329444</td>\n",
       "      <td>Add Promise as a child test to Flight fixture ...</td>\n",
       "      <td>add promise child test flight fixture add test...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0            [DOM] Fix package.json files for #28784   \n",
       "1  [DOM] disallow client entrypoints with react-s...   \n",
       "2               [TestUtils] Build limited test-utils   \n",
       "3    [Flight] Allow lazily resolving outlined models   \n",
       "4      Add Promise as a child test to Flight fixture   \n",
       "\n",
       "                                                body  \\\n",
       "0  Missed some files for the react-server disallo...   \n",
       "1  `react-server` precludes loading code that exp...   \n",
       "2  We landed a flag to disable test utils in many...   \n",
       "3  We used to assume that outlined models are emi...   \n",
       "4  Adds a test for promise as a child that was fi...   \n",
       "\n",
       "                 created_at                 closed_at  is_pull_request  \\\n",
       "0 2024-04-08 22:41:51+00:00 2024-04-08 22:49:19+00:00             True   \n",
       "1 2024-04-08 22:26:02+00:00 2024-04-08 22:37:06+00:00             True   \n",
       "2 2024-04-08 18:02:46+00:00 2024-04-08 19:27:20+00:00             True   \n",
       "3 2024-04-08 15:24:01+00:00 2024-04-08 19:40:11+00:00             True   \n",
       "4 2024-04-08 10:46:31+00:00 2024-04-08 15:06:17+00:00             True   \n",
       "\n",
       "  author_association  time_to_close_hours  \\\n",
       "0       COLLABORATOR             0.124444   \n",
       "1       COLLABORATOR             0.184444   \n",
       "2       COLLABORATOR             1.409444   \n",
       "3       COLLABORATOR             4.269444   \n",
       "4       COLLABORATOR             4.329444   \n",
       "\n",
       "                                                text  \\\n",
       "0  [DOM] Fix package.json files for #28784 Missed...   \n",
       "1  [DOM] disallow client entrypoints with react-s...   \n",
       "2  [TestUtils] Build limited test-utils We landed...   \n",
       "3  [Flight] Allow lazily resolving outlined model...   \n",
       "4  Add Promise as a child test to Flight fixture ...   \n",
       "\n",
       "                                         text_parsed  \n",
       "0  dom fix packagejson file 28784 miss file react...  \n",
       "1  dom disallow client entrypoints reactserver co...  \n",
       "2  testutils build limit testutils land flag disa...  \n",
       "3  flight allow lazily resolve outline model use ...  \n",
       "4  add promise child test flight fixture add test...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_association_dummies = pd.get_dummies(df['author_association'], prefix='author')\n",
    "df = pd.concat([df, author_association_dummies], axis=1)\n",
    "\n",
    "df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "\n",
    "# Ensure the data is sorted chronologically based on 'created_at'\n",
    "df = df.sort_values('created_at')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Split your data chronologically into train and test sets\n",
    "# Let's say 80% for training and 20% for testing as an example\n",
    "split_point = int(len(df) * 0.8)\n",
    "train_data = df.iloc[:split_point, :]\n",
    "test_data = df.iloc[split_point:, :]\n",
    "\n",
    "# Define the columns to drop (columns not used as features for training)\n",
    "columns_to_drop = ['created_at', 'closed_at', 'title', 'body', 'author_association', 'text']\n",
    "\n",
    "# Drop the unnecessary columns and split the data into features and target\n",
    "X_train = train_data.drop(columns=columns_to_drop , axis=1)\n",
    "y_train = train_data['time_to_close_hours']\n",
    "\n",
    "X_test = test_data.drop(columns=columns_to_drop, axis=1)\n",
    "y_test = test_data['time_to_close_hours']\n",
    "\n",
    "# Handle any NaNs in target variable 'time_to_close' if needed\n",
    "X_train = X_train[y_train.notnull()]\n",
    "y_train = y_train[y_train.notnull()]\n",
    "\n",
    "X_test = X_test[y_test.notnull()]\n",
    "y_test = y_test[y_test.notnull()]\n",
    "\n",
    "X_train['is_pull_request'] = X_train['is_pull_request'].astype(int)\n",
    "X_test['is_pull_request'] = X_test['is_pull_request'].astype(int)\n",
    "\n",
    "author_columns = ['author_COLLABORATOR', 'author_CONTRIBUTOR', 'author_MEMBER', 'author_NONE']\n",
    "\n",
    "# Convert each author_* column to numeric\n",
    "for col in author_columns:\n",
    "    X_train[col] = X_train[col].astype(int)\n",
    "    X_test[col] = X_test[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_pull_request</th>\n",
       "      <th>time_to_close_hours</th>\n",
       "      <th>text_parsed</th>\n",
       "      <th>author_COLLABORATOR</th>\n",
       "      <th>author_CONTRIBUTOR</th>\n",
       "      <th>author_MEMBER</th>\n",
       "      <th>author_NONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>117.619167</td>\n",
       "      <td>run test iframe block initial launch feel free...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>docs fix button link bottom home button index ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>docs fix couple minor typosspelling</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>docs improve event handle documentation add ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>fix link root readmemd</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_pull_request  time_to_close_hours  \\\n",
       "0                1           117.619167   \n",
       "1                1             0.012778   \n",
       "2                1             0.033333   \n",
       "3                1             0.004722   \n",
       "4                1             0.014444   \n",
       "\n",
       "                                         text_parsed  author_COLLABORATOR  \\\n",
       "0  run test iframe block initial launch feel free...                    0   \n",
       "1  docs fix button link bottom home button index ...                    0   \n",
       "2                docs fix couple minor typosspelling                    0   \n",
       "3  docs improve event handle documentation add ad...                    0   \n",
       "4                             fix link root readmemd                    0   \n",
       "\n",
       "   author_CONTRIBUTOR  author_MEMBER  author_NONE  \n",
       "0                   1              0            0  \n",
       "1                   1              0            0  \n",
       "2                   1              0            0  \n",
       "3                   1              0            0  \n",
       "4                   1              0            0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "import torch\n",
    "\n",
    "class BertRegressorWithFeatures(nn.Module):\n",
    "    def __init__(self, additional_feature_size):\n",
    "        super(BertRegressorWithFeatures, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Assuming the BERT output size and additional features. Adjust `additional_feature_size` accordingly.\n",
    "        self.regressor = nn.Linear(self.bert.config.hidden_size + additional_feature_size, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, additional_features):\n",
    "        # Get the pooled output from BERT\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        \n",
    "        # Concatenate the BERT output with the additional features\n",
    "        combined_features = torch.cat((pooled_output, additional_features), dim=1)\n",
    "        \n",
    "        # Pass the combined features through the regressor for the final prediction\n",
    "        return self.regressor(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_additional_features = X_train[['is_pull_request', 'author_COLLABORATOR', 'author_CONTRIBUTOR', 'author_MEMBER', 'author_NONE']].to_numpy()\n",
    "test_additional_features = X_test[['is_pull_request', 'author_COLLABORATOR', 'author_CONTRIBUTOR', 'author_MEMBER', 'author_NONE']].to_numpy()\n",
    "labels = df['time_to_close_hours'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize training and testing text data\n",
    "train_encodings = tokenizer(X_train['text_parsed'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(X_test['text_parsed'].tolist(), truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class GitHubIssuesDataset(Dataset):\n",
    "    def __init__(self, encodings, additional_features, labels):\n",
    "        self.encodings = encodings\n",
    "        self.additional_features = additional_features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['additional_features'] = torch.tensor(self.additional_features[idx], dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = GitHubIssuesDataset(train_encodings, train_additional_features, y_train)\n",
    "test_dataset = GitHubIssuesDataset(test_encodings, test_additional_features, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenxiyang/Desktop/study/18668DS/Individual/env/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertRegressorWithFeatures(additional_feature_size=5).to(device)  # Update `additional_feature_size` as necessary\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        additional_features = batch['additional_features'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask, additional_features)\n",
    "        loss = nn.MSELoss()(outputs, labels.unsqueeze(-1))  # Ensure labels are correctly shaped\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "from math import sqrt\n",
    "\n",
    "def calculate_rmse(model, data_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_mse = 0\n",
    "    with torch.no_grad():  # No gradients needed\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            additional_features = batch['additional_features'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask, additional_features)\n",
    "            \n",
    "            # Assuming your model returns the predictions directly\n",
    "            # You may need to adjust this if your model output structure is different\n",
    "            mse = mse_loss(outputs.squeeze(), labels)  # Ensure the shapes align\n",
    "            total_mse += mse.item() * len(labels)  # Accumulate the total MSE\n",
    "\n",
    "    # Calculate mean MSE then RMSE\n",
    "    mean_mse = total_mse / len(data_loader.dataset)\n",
    "    rmse = sqrt(mean_mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = calculate_rmse(model, train_loader, device)\n",
    "test_rmse = calculate_rmse(model, test_loader, device)\n",
    "\n",
    "print(f\"Training RMSE: {train_rmse}\")\n",
    "print(f\"Testing RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_time_to_close.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
